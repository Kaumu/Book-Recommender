{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import correlation\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Country</th>\n",
       "      <th>Category</th>\n",
       "      <th>Age_groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>Flesh Tones  A Novel</td>\n",
       "      <td>M  J  Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>USA</td>\n",
       "      <td>Latest</td>\n",
       "      <td>(10.0, 30.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>Flesh Tones  A Novel</td>\n",
       "      <td>M  J  Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>USA</td>\n",
       "      <td>Latest</td>\n",
       "      <td>(10.0, 30.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Flesh Tones  A Novel</td>\n",
       "      <td>M  J  Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>USA</td>\n",
       "      <td>Latest</td>\n",
       "      <td>(30.0, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Flesh Tones  A Novel</td>\n",
       "      <td>M  J  Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>USA</td>\n",
       "      <td>Latest</td>\n",
       "      <td>(30.0, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>Flesh Tones  A Novel</td>\n",
       "      <td>M  J  Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>USA</td>\n",
       "      <td>Latest</td>\n",
       "      <td>(10.0, 30.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating  Age            Book-Title Book-Author  \\\n",
       "0   276725  034545104X            0   18  Flesh Tones  A Novel  M  J  Rose   \n",
       "1     2313  034545104X            5   23  Flesh Tones  A Novel  M  J  Rose   \n",
       "2     6543  034545104X            5   34  Flesh Tones  A Novel  M  J  Rose   \n",
       "3     8680  034545104X            5   34  Flesh Tones  A Novel  M  J  Rose   \n",
       "4    10314  034545104X            9   13  Flesh Tones  A Novel  M  J  Rose   \n",
       "\n",
       "   Year-Of-Publication         Publisher Country Category    Age_groups  \n",
       "0                 2002  Ballantine Books     USA   Latest  (10.0, 30.0]  \n",
       "1                 2002  Ballantine Books     USA   Latest  (10.0, 30.0]  \n",
       "2                 2002  Ballantine Books     USA   Latest  (30.0, 50.0]  \n",
       "3                 2002  Ballantine Books     USA   Latest  (30.0, 50.0]  \n",
       "4                 2002  Ballantine Books     USA   Latest  (10.0, 30.0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import your cleaned dataset\n",
    "cdata = pd.read_csv(\"/Users/kaumudi/Documents/Data Intensive Computing/Project_1/Cleaned_Data.csv\", error_bad_lines= False, encoding = \"latin_1\")\n",
    "users = pd.read_csv(\"/Users/kaumudi/Documents/Data Intensive Computing/Project_1/Cleaned_Users.csv\",  error_bad_lines= False, encoding = \"latin_1\")\n",
    "books = pd.read_csv(\"/Users/kaumudi/Documents/Data Intensive Computing/Project_1/Cleaned_Books.csv\",  error_bad_lines= False, encoding = \"latin_1\")\n",
    "ratings = pd.read_csv(\"/Users/kaumudi/Documents/Data Intensive Computing/Project_1/Cleaned_Ratings.csv\", error_bad_lines= False, encoding = \"latin_1\")\n",
    "# display the first five rows data.head(5)\n",
    "cdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns = ['User_ID', 'ISBN', 'Book_Rating']\n",
    "users.columns = ['User_ID', 'Location', 'Age']\n",
    "books.columns = ['ISBN', 'Book_Title', 'Book_Author', 'Year_Of_Publication', 'Publisher', 'Image_URL_S', 'Image_URL_M','Image_URL_L' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = model_selection.train_test_split(df, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set lengths: 706463\n",
      "Testing set lengths: 176616\n",
      "Test set is 20% of the full dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set lengths: {len(train_data)}')\n",
    "print(f'Testing set lengths: {len(test_data)}')\n",
    "print(f'Test set is {(len(test_data)/(len(train_data)+len(test_data))*100):.0f}% of the full dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get int mapping for user_id in train dataset\n",
    "\n",
    "u_unique_train = train_data['User-ID'].unique()  \n",
    "train_data_user2idx = {o:i for i, o in enumerate(u_unique_train)}\n",
    "\n",
    "# Get int mapping for isbn in train dataset\n",
    "\n",
    "i_unique_train = train_data['ISBN'].unique()  \n",
    "train_data_book2idx = {o:i for i, o in enumerate(i_unique_train)}\n",
    "\n",
    "# Get int mapping for user_id in test dataset\n",
    "\n",
    "u_unique_test = test_data['User-ID'].unique()  \n",
    "test_data_user2idx = {o:i for i, o in enumerate(u_unique_test)}\n",
    "\n",
    "# Get int mapping for isbn in train dataset\n",
    "\n",
    "i_unique_test = test_data['ISBN'].unique() \n",
    "test_data_book2idx = {o:i for i, o in enumerate(i_unique_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-d0b4f7d99787>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['u_unique'] = train_data['User-ID'].map(train_data_user2idx)\n",
      "<ipython-input-11-d0b4f7d99787>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['i_unique'] = train_data['ISBN'].map(train_data_book2idx)\n",
      "<ipython-input-11-d0b4f7d99787>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['u_unique'] = test_data['User-ID'].map(test_data_user2idx)\n",
      "<ipython-input-11-d0b4f7d99787>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['i_unique'] = test_data['ISBN'].map(test_data_book2idx)\n"
     ]
    }
   ],
   "source": [
    "# TRAINING SET\n",
    "train_data['u_unique'] = train_data['User-ID'].map(train_data_user2idx)\n",
    "train_data['i_unique'] = train_data['ISBN'].map(train_data_book2idx)\n",
    "\n",
    "# TESTING SET\n",
    "test_data['u_unique'] = test_data['User-ID'].map(test_data_user2idx)\n",
    "test_data['i_unique'] = test_data['ISBN'].map(test_data_book2idx)\n",
    "\n",
    "# Convert back to 3-column df\n",
    "train_data = train_data[['u_unique', 'i_unique', 'Book-Rating']]\n",
    "test_data = test_data[['u_unique', 'i_unique', 'Book-Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = train_data['u_unique'].nunique()\n",
    "n_books = train_data['i_unique'].nunique()\n",
    "\n",
    "train_matrix = np.zeros((n_users, n_books))\n",
    "\n",
    "for entry in train_data.itertuples():                  # entry[1] is the user-id, entry[2] is the book-isbn\n",
    "    train_matrix[entry[1]-1, entry[2]-1] = entry[3]    # -1 is to counter 0-based indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74169, 212760)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = test_data['u_unique'].nunique()\n",
    "n_books = test_data['i_unique'].nunique()\n",
    "\n",
    "test_matrix = np.zeros((n_users, n_books))\n",
    "\n",
    "for entry in test_data.itertuples():\n",
    "    test_matrix[entry[1]-1, entry[2]-1] = entry[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33766, 87077)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_matrix_small = train_matrix[:5000, :5000]\n",
    "test_matrix_small = test_matrix[:5000, :5000]\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_matrix_small, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_matrix_small.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_books(ratings, similarity, type='user'): # default type is 'user'\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        \n",
    "        # Use np.newaxis so that mean_user_rating has the same format as ratings\n",
    "        \n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict_books(train_matrix_small, item_similarity, type='item')\n",
    "user_prediction = predict_books(train_matrix_small, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF train data RMSE: 7.697668355475874\n",
      "User-based CF test data RMSE: 7.8316706885867235\n",
      "Item-based CF train data RMSE: 7.781228271204122\n",
      "Item-based CF test data RMSE: 7.833199499274285\n"
     ]
    }
   ],
   "source": [
    "def rmse(pred, actual):\n",
    "    # ignore nonzeros items\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(pred, actual))\n",
    "\n",
    "\n",
    "train_user = rmse(user_prediction, train_matrix_small)\n",
    "test_user = rmse(user_prediction, test_matrix_small)\n",
    "print(f'User-based CF train data RMSE: {train_user}')\n",
    "print(f'User-based CF test data RMSE: {test_user}')\n",
    "\n",
    "train_item = rmse(item_prediction, train_matrix_small)\n",
    "test_item = rmse(item_prediction, test_matrix_small)\n",
    "print(f'Item-based CF train data RMSE: {train_item}')\n",
    "print(f'Item-based CF test data RMSE: {test_item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['User-based', 'Item-based']\n",
    "user_means = [train_user, test_user]\n",
    "item_means = [train_item, test_item]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.15  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, user_means, width, label='User')\n",
    "rects2 = ax.bar(x + width/2, item_means, width, label='Item')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('RMSE Scores for training and test data')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# ax.bar_label(rects1, padding=3)\n",
    "# ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from surprise) (1.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise->surprise) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise->surprise) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise->surprise) (0.17.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise->surprise) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns = ['User_ID', 'ISBN', 'Book_Rating']\n",
    "users.columns = ['User_ID', 'Location', 'Age']\n",
    "books.columns = ['ISBN', 'Book_Title', 'Book_Author', 'Year_Of_Publication', 'Publisher']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from sortedcontainers import SortedList\n",
    "from utils import *\n",
    "\n",
    "from BookData import BookDataSet\n",
    "from EvaluationData import CreateDataSets\n",
    "from EvaluatedAlgorithm import EvaluatedAlgorithm\n",
    "\n",
    "\n",
    "class SimpleCollaborativeFiltering:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors Collaborative Filtering System\n",
    "    \n",
    "    Attributes:\n",
    "        data (object): surprise Book Dataset object\n",
    "        k (int): number of books to recommend \n",
    "        max_rating (float): max rating in dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ratings, books, users, k=10, max_rating=10.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ratings (pandas df): ratings dataframe \n",
    "            books (pandas df): book information dataframe \n",
    "            users (pandas df): user information dataframe\n",
    "            k (int): number of books to recommend \n",
    "            max_rating (float): max rating in dataset\n",
    "        \"\"\"\n",
    "        self.data = BookDataSet(ratings, books, users)\n",
    "        self.k = k\n",
    "        self.max_rating = max_rating\n",
    "        \n",
    "    def get_neighbors(self, user_id, user_based_=True, metric='cosine', verbose=False):\n",
    "        \"\"\"\n",
    "        Trains a model based on user based CF or item based CF\n",
    "        Computes interation matrix and returns matrix and rows correspoonding with the user \n",
    "        Args:\n",
    "            user_id (int): user id \n",
    "            user_based_ (boolean): use user based CF (True) or item based CF (False)\n",
    "            metric (str): similarity metric \n",
    "            verbose (boolean): print output \n",
    "        Returns:\n",
    "            interations (surprise matrix): similarity matrix \n",
    "            similarity_rows (list): user rows \n",
    "        \"\"\"\n",
    "        # create model\n",
    "        self.train = self.data.build_full_trainset()\n",
    "        sim_options = {'name': metric,\n",
    "                       'user_based': user_based_\n",
    "        }\n",
    "        model = KNNBasic(sim_options=sim_options, verbose=verbose)\n",
    "        model.fit(self.train)\n",
    "        interations = model.compute_similarities()\n",
    "\n",
    "        self.surprise_user_id = self.train.to_inner_uid(user_id)\n",
    "        similarity_rows = interations[self.surprise_user_id]\n",
    "        return interations, similarity_rows\n",
    "\n",
    "    def show_top_books(self, candidates, watched_list):\n",
    "        \"\"\"\n",
    "        Prints out top K books and corresponding score \n",
    "        Args:\n",
    "            candidates (defaultdict): book id and score ({book_id:score})\n",
    "            watched_list (list): list of books that the user has already seen\n",
    "        \"\"\"\n",
    "        # print out top 10 books and score \n",
    "        N = 0\n",
    "        print('Top {} Book Recommendations:'.format(self.k))\n",
    "        print('\\n')\n",
    "        for item_id, ratings in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "            if item_id not in watched_list:\n",
    "                book_id = self.train.to_raw_iid(item_id)\n",
    "                book_name = self.data.get_book_name(book_id)\n",
    "                book_author = self.data.get_book_author(book_id)\n",
    "                book_year = self.data.get_book_year(book_id)\n",
    "                try:\n",
    "                    book_year = int(book_year) \n",
    "                except:\n",
    "                    book_year = 'Not Available'\n",
    "                print('{} - {} - ({}) - Score: {}'.format(book_name, book_author, book_year, round(ratings, 2)))\n",
    "                N += 1\n",
    "                if (N > self.k): break\n",
    "        \n",
    "    def user_based(self, user_id, threshold=False):\n",
    "        \"\"\"\n",
    "        User based Collaborative Filtering \n",
    "        Args:\n",
    "            user_id (int): user id \n",
    "            threshold (boolean): only use similar users above .95 correlation\n",
    "        \"\"\"\n",
    "        _, similarity_rows = self.get_neighbors(user_id)\n",
    "        \n",
    "        similar_users = SortedList(key=lambda x: -x[1])\n",
    "        for i, score in enumerate(similarity_rows):\n",
    "            if i != user_id:\n",
    "                similar_users.add((i, score))\n",
    "        \n",
    "        if threshold:\n",
    "            similar_users = [rating for rating in similar_users if rating[1] >= 0.95]\n",
    "\n",
    "        candidates = defaultdict(float)\n",
    "        for similar_user in similar_users[:self.k]:\n",
    "            surprise_sim_user_idx, score = similar_user\n",
    "            sim_user_rating = self.train.ur[surprise_sim_user_idx]\n",
    "            for info in sim_user_rating:\n",
    "                book_id, rating = info\n",
    "                # use += and increase weight for books that appear more than once \n",
    "                candidates[book_id] += (rating / self.max_rating) * score\n",
    "\n",
    "        # list of books that the user has seen\n",
    "        watched_list = [book_id for book_id, rating in self.train.ur[self.surprise_user_id]]\n",
    "\n",
    "        # Get top-rated items from similar users\n",
    "        self.show_top_books(candidates, watched_list)\n",
    "        \n",
    "    def item_based(self, user_id, threshold=False):\n",
    "        \"\"\"\n",
    "        Item based Collaborative Filtering \n",
    "        Args:\n",
    "            user_id (int): user id \n",
    "            threshold (boolean): only use similar users above .95 correlation\n",
    "        \"\"\"\n",
    "        interations, _ = self.get_neighbors(user_id, user_based_=False)\n",
    "\n",
    "        # Get the top K items we rated\n",
    "        test_user_ratings = self.train.ur[self.surprise_user_id]\n",
    "\n",
    "        if threshold:\n",
    "            kNeighbors = [rating for rating in test_user_ratings if rating[1] >= 7.0]\n",
    "        else:\n",
    "            kNeighbors = heapq.nlargest(self.k, test_user_ratings, key=lambda t: t[1])\n",
    "        \n",
    "        # Get similar items to stuff we liked (weighted by rating)\n",
    "        candidates = defaultdict(float)\n",
    "        for item_id, rating in kNeighbors:\n",
    "            similarity_row = interations[item_id]\n",
    "            for inner_id, score in enumerate(similarity_row):\n",
    "                candidates[inner_id] += score * (rating / 10.0)\n",
    "\n",
    "        # list of books that the user has seen\n",
    "        watched_list = [book_id for book_id, rating in self.train.ur[self.surprise_user_id]]\n",
    "        \n",
    "        # Get top-rated items from similar items\n",
    "        self.show_top_books(candidates, watched_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book_Title</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>0553296981</td>\n",
       "      <td>Anne Frank  The Diary of a Young Girl</td>\n",
       "      <td>ANNE FRANK</td>\n",
       "      <td>1993</td>\n",
       "      <td>Bantam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>0515131091</td>\n",
       "      <td>Out of This World</td>\n",
       "      <td>J  D  Robb</td>\n",
       "      <td>2001</td>\n",
       "      <td>Jove Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>0373273193</td>\n",
       "      <td>Racing Against Time   Cavanaugh Justice  Intim...</td>\n",
       "      <td>Marie Ferrarella</td>\n",
       "      <td>2003</td>\n",
       "      <td>Silhouette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>0671003518</td>\n",
       "      <td>The BRIDE   PROMOTIONAL</td>\n",
       "      <td>Julie Garwood</td>\n",
       "      <td>1996</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>0671034065</td>\n",
       "      <td>Mr  Perfect</td>\n",
       "      <td>Linda Howard</td>\n",
       "      <td>2000</td>\n",
       "      <td>Atria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ISBN                                         Book_Title  \\\n",
       "1289  0553296981              Anne Frank  The Diary of a Young Girl   \n",
       "2038  0515131091                                  Out of This World   \n",
       "2084  0373273193  Racing Against Time   Cavanaugh Justice  Intim...   \n",
       "3077  0671003518                            The BRIDE   PROMOTIONAL   \n",
       "3159  0671034065                                        Mr  Perfect   \n",
       "\n",
       "           Book_Author  Year_Of_Publication   Publisher  \n",
       "1289        ANNE FRANK                 1993      Bantam  \n",
       "2038        J  D  Robb                 2001  Jove Books  \n",
       "2084  Marie Ferrarella                 2003  Silhouette  \n",
       "3077     Julie Garwood                 1996      Pocket  \n",
       "3159      Linda Howard                 2000       Atria  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample user (this user seems to like action and exciting books )\n",
    "# 234828, 89602, 69697\n",
    "USER_ID = 69697\n",
    "books[books.ISBN.isin(ratings.loc[(ratings.User_ID == USER_ID) & (ratings.Book_Rating > 8), 'ISBN'])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Ratings Shape (396585, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISBN</th>\n",
       "      <th>0375404120</th>\n",
       "      <th>9022906116</th>\n",
       "      <th>000000000</th>\n",
       "      <th>0000000000</th>\n",
       "      <th>00000000000</th>\n",
       "      <th>0000000029841</th>\n",
       "      <th>000104799X</th>\n",
       "      <th>0001048082</th>\n",
       "      <th>0001052276</th>\n",
       "      <th>0001056107</th>\n",
       "      <th>...</th>\n",
       "      <th>B000133Q02</th>\n",
       "      <th>B00016560C</th>\n",
       "      <th>B0001GMSV2</th>\n",
       "      <th>CARD#6920006</th>\n",
       "      <th>CN102273</th>\n",
       "      <th>CN108081</th>\n",
       "      <th>FUNNYSAUCE</th>\n",
       "      <th>O316666343</th>\n",
       "      <th>O67174142X</th>\n",
       "      <th>O77O428452</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ISBN      0375404120   9022906116  000000000  0000000000  00000000000  \\\n",
       "User_ID                                                                 \n",
       "254              0.0          0.0        0.0         0.0          0.0   \n",
       "2276             0.0          0.0        0.0         0.0          0.0   \n",
       "2766             0.0          0.0        0.0         0.0          0.0   \n",
       "2977             0.0          0.0        0.0         0.0          0.0   \n",
       "3363             0.0          0.0        0.0         0.0          0.0   \n",
       "\n",
       "ISBN     0000000029841  000104799X  0001048082  0001052276  0001056107  ...  \\\n",
       "User_ID                                                                 ...   \n",
       "254                0.0         0.0         0.0         0.0         0.0  ...   \n",
       "2276               0.0         0.0         0.0         0.0         0.0  ...   \n",
       "2766               0.0         0.0         0.0         0.0         0.0  ...   \n",
       "2977               0.0         0.0         0.0         0.0         0.0  ...   \n",
       "3363               0.0         0.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "ISBN     B000133Q02  B00016560C  B0001GMSV2  CARD#6920006  CN102273  CN108081  \\\n",
       "User_ID                                                                         \n",
       "254             0.0         0.0         0.0           0.0       0.0       0.0   \n",
       "2276            0.0         0.0         0.0           0.0       0.0       0.0   \n",
       "2766            0.0         0.0         0.0           0.0       0.0       0.0   \n",
       "2977            0.0         0.0         0.0           0.0       0.0       0.0   \n",
       "3363            0.0         0.0         0.0           0.0       0.0       0.0   \n",
       "\n",
       "ISBN     FUNNYSAUCE  O316666343  O67174142X  O77O428452  \n",
       "User_ID                                                  \n",
       "254             0.0         0.0         0.0         0.0  \n",
       "2276            0.0         0.0         0.0         0.0  \n",
       "2766            0.0         0.0         0.0         0.0  \n",
       "2977            0.0         0.0         0.0         0.0  \n",
       "3363            0.0         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 76728 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ratings = popular_ratings(ratings, user_threshold=200, rating_threshold=200, book_threshold=1)\n",
    "print('Sample Ratings Shape', sample_ratings.shape)\n",
    "book_ratings = sample_ratings.pivot_table(index='User_ID', columns='ISBN', values='Book_Rating').fillna(0)\n",
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create k-Nearest Neighbors Collaborative Filtering model \n",
    "cf = SimpleCollaborativeFiltering(sample_ratings, books, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Book Recommendations:\n",
      "\n",
      "\n",
      "Harry Potter and the Chamber of Secrets  Book 2  - J  K  Rowling - (2000) - Score: 0.45\n",
      "The Devil You Know - Poppy Z  Brite - (2003) - Score: 0.45\n",
      "Short  amp  Tall Tales  Moose County Legends Collected by James Mackintosh Qwilleran - Lilian Jackson Braun - (2002) - Score: 0.4\n",
      "Politically Correct Bedtime Stories  Modern Tales for Our Life and Times - James Finn Garner - (1994) - Score: 0.0\n",
      "Vegetarian Times Complete Cookbook - Lucy  Moll - (1995) - Score: 0.0\n",
      "On Writing Well  25th Anniversary   The Classic Guide to Writing Nonfiction  On Writing Well  - William Zinsser - (2001) - Score: 0.0\n",
      "The World of Jeeves - P G  Wodehouse - (1989) - Score: 0.0\n",
      " -  - (Not Available) - Score: 0.0\n",
      "Beauty Fades  Dumb Is Forever  The Making of a Happy Woman - Judy Sheindlin - (1999) - Score: 0.0\n",
      "In Country RI - Bobbie Ann Mason - (1986) - Score: 0.0\n",
      "A Tree Grows in Brooklyn - Betty Smith - (1998) - Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors user based collaborative filtering \n",
    "cf.user_based(user_id=USER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book_Title</th>\n",
       "      <th>Book_Author</th>\n",
       "      <th>Year_Of_Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>042511774X</td>\n",
       "      <td>Breathing Lessons</td>\n",
       "      <td>Anne Tyler</td>\n",
       "      <td>1994</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>0345370775</td>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>Michael Crichton</td>\n",
       "      <td>1999</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0451191153</td>\n",
       "      <td>The Fountainhead</td>\n",
       "      <td>Ayn Rand</td>\n",
       "      <td>1996</td>\n",
       "      <td>New American Library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>0345380371</td>\n",
       "      <td>Rising Sun</td>\n",
       "      <td>MICHAEL CRICHTON</td>\n",
       "      <td>1992</td>\n",
       "      <td>Ballantine Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0553343874</td>\n",
       "      <td>Emmanuel s Book  A Manual for Living Comfortab...</td>\n",
       "      <td>Pat Rodegast</td>\n",
       "      <td>1987</td>\n",
       "      <td>Bantam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ISBN                                         Book_Title  \\\n",
       "66    042511774X                                  Breathing Lessons   \n",
       "1173  0345370775                                      Jurassic Park   \n",
       "1463  0451191153                                   The Fountainhead   \n",
       "1815  0345380371                                         Rising Sun   \n",
       "1926  0553343874  Emmanuel s Book  A Manual for Living Comfortab...   \n",
       "\n",
       "           Book_Author  Year_Of_Publication                 Publisher  \n",
       "66          Anne Tyler                 1994  Berkley Publishing Group  \n",
       "1173  Michael Crichton                 1999          Ballantine Books  \n",
       "1463          Ayn Rand                 1996      New American Library  \n",
       "1815  MICHAEL CRICHTON                 1992          Ballantine Books  \n",
       "1926      Pat Rodegast                 1987                    Bantam  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample user (this user seems to like action and exciting books )\n",
    "# 234828, 89602, 69697\n",
    "USER_ID = 234828\n",
    "books[books.ISBN.isin(ratings.loc[(ratings.User_ID == USER_ID) & (ratings.Book_Rating > 8), 'ISBN'])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create k-Nearest Neighbors Collaborative Filtering model \n",
    "cf = SimpleCollaborativeFiltering(sample_ratings, books, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Nearest Neighbors item based collaborative filtering \n",
    "cf.item_based(user_id=USER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_explicit = df[df['Book-Rating'] != 0]\n",
    "ratings_implicit = df[df['Book-Rating'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_explicit = ratings_explicit[['User-ID', 'ISBN', 'Book-Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23768</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883074</th>\n",
       "      <td>276688</td>\n",
       "      <td>0425150526</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883075</th>\n",
       "      <td>276688</td>\n",
       "      <td>0449907422</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883076</th>\n",
       "      <td>276690</td>\n",
       "      <td>0590907301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883077</th>\n",
       "      <td>276704</td>\n",
       "      <td>0679752714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883078</th>\n",
       "      <td>276704</td>\n",
       "      <td>0806917695</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>883078 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID        ISBN  Book-Rating\n",
       "1          2313  034545104X            5\n",
       "2          6543  034545104X            5\n",
       "3          8680  034545104X            5\n",
       "4         10314  034545104X            9\n",
       "5         23768  034545104X            9\n",
       "...         ...         ...          ...\n",
       "883074   276688  0425150526            5\n",
       "883075   276688  0449907422            5\n",
       "883076   276690  0590907301            5\n",
       "883077   276704  0679752714            5\n",
       "883078   276704  0806917695            5\n",
       "\n",
       "[883078 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "# Creating a 'Reader' object to set the limit of the ratings \n",
    "\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "data = Dataset.load_from_df(ratings_explicit, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.7048  1.7093  1.7147  1.7120  1.7164  1.7114  0.0041  \n",
      "MAE (testset)     1.3500  1.3527  1.3559  1.3555  1.3594  1.3547  0.0032  \n",
      "Fit time          41.41   42.54   41.67   42.05   40.97   41.73   0.54    \n",
      "Test time         1.24    1.48    1.23    1.15    1.20    1.26    0.11    \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, model_selection, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "model = SVD()\n",
    "\n",
    "# Train on books dataset\n",
    "\n",
    "xyz = cross_validate(model, data, measures=['RMSE','MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_Rmse = xyz.get('test_rmse')\n",
    "svd_Mae = xyz.get('test_mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.70476948, 1.70927577, 1.71466049, 1.71198239, 1.71640697]),\n",
       " array([1.34995576, 1.35267569, 1.35586214, 1.35546208, 1.35938505]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_Rmse, svd_Mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7099572856268443"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into train and test sets\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=0.2)\n",
    "\n",
    "# model1 = NMF()\n",
    "model.fit(trainset)\n",
    "\n",
    "#Tested model and found the predictions\n",
    "predictions = model.test(testset)\n",
    "\n",
    "#Calculated RMSE score\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3756  2.3791  2.3794  2.3653  2.3638  2.3726  0.0067  \n",
      "MAE (testset)     2.0132  2.0174  2.0176  2.0042  2.0026  2.0110  0.0064  \n",
      "Fit time          58.07   58.64   59.15   59.11   58.06   58.60   0.48    \n",
      "Test time         1.27    1.19    1.26    1.25    1.20    1.23    0.03    \n"
     ]
    }
   ],
   "source": [
    "from surprise import NMF\n",
    "#Create NMF model to cpmare with SVD\n",
    "model1 = NMF()\n",
    "\n",
    "# Train on books dataset\n",
    "nmfData = cross_validate(model1, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfRmse = nmfData.get('test_rmse')\n",
    "nmfMae = nmfData.get('test_mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.37558605, 2.37909268, 2.37937566, 2.36527581, 2.3638154 ]),\n",
       " array([2.01322949, 2.01743113, 2.01755329, 2.00419249, 2.00256438]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmfRmse, nmfMae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.3865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.386536323362893"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data into train and test sets\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=0.2)\n",
    "\n",
    "# model1 = NMF()\n",
    "model1.fit(trainset)\n",
    "\n",
    "#Tested model and found the predictions\n",
    "predictions = model1.test(testset)\n",
    "\n",
    "#Calculated RMSE score\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_fields(x, combine=False):\n",
    "    \"\"\"clean string field\"\"\"\n",
    "    x = x.lower()\n",
    "    x = re.sub('[^a-z0-9 ]', '', x)\n",
    "    if combine:\n",
    "        return ''.join(x.replace(' ', '') for x in x).strip()\n",
    "    return x.strip()\n",
    "\n",
    "# sort and return top\n",
    "def sort_sims(sim_scores, topN=10):\n",
    "    \"\"\"sort scores by value of dict and return topN results\"\"\"\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    return sim_scores[:topN+1]\n",
    "        \n",
    "\n",
    "\n",
    "class ContentBased(object):\n",
    "    \"\"\"\n",
    "    Content Based Filtering\n",
    "\n",
    "    Attributes:\n",
    "        ratings (pandas df): ratings dataframe \n",
    "        books (pandas df): book information dataframe \n",
    "        cosine_sim (sparse matrix): cosine similarity matrix\n",
    "        indices (pandas df): Book Title Series \n",
    "    \"\"\"\n",
    "    def __init__(self, ratings, books):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ratings (pandas df): ratings dataframe \n",
    "            books (pandas df): book information dataframe \n",
    "        \"\"\"\n",
    "        self.ratings = ratings\n",
    "        books = self.prepare_data(books, ratings)\n",
    "        self.cosine_sim, self.books, self.indices = self.compute_similarity(books)\n",
    "        \n",
    "    def prepare_data(self, books, ratings, rating_threshold=2):\n",
    "        \"\"\"\n",
    "        Cleans and subsets book dataframe\n",
    "        Args:\n",
    "            ratings (pandas df): ratings dataframe \n",
    "            books (pandas df): book information dataframe\n",
    "            rating_threshold (int): threshold to limit rating count \n",
    "        Returns:\n",
    "            books (pandas df): book information dataframe \n",
    "        \"\"\"\n",
    "        books = books[books['ISBN'].isin(ratings['ISBN'])]\n",
    "        books = books.drop_duplicates(subset=['Book-Title'])\n",
    "        most_popular_ISBN = list(ratings['ISBN'].value_counts()[ratings['ISBN'].value_counts() >= rating_threshold].index)\n",
    "        books = books[books.ISBN.isin(most_popular_ISBN)]\n",
    "        books['Publisher'] = books['Publisher'].map(lambda x: clean_fields(x, combine=True))\n",
    "        books['Book-Author'] = books['Book-Author'].map(lambda x: clean_fields(x, combine=True))\n",
    "        books['Book-Title-Clean'] = books['Book-Title'].map(lambda x: clean_fields(x, combine=False))\n",
    "        books['soup'] = books['Book-Title-Clean'] + ' ' + books['Book-Author'] + ' ' + books['Publisher']\n",
    "        return books \n",
    "        \n",
    "    def compute_similarity(self, books):\n",
    "        \"\"\"\n",
    "        Creates BOW model on the combined book text fields and computes similarity\n",
    "        Args:\n",
    "            books (pandas df): book information dataframe\n",
    "        Returns:\n",
    "            books (pandas df): book information dataframe \n",
    "            cosine_sim (sparse matrix): cosine similarity matrix\n",
    "            indices (pandas df): Book Title Series  \n",
    "        \"\"\"\n",
    "        vect = CountVectorizer(stop_words='english', max_features=1000)\n",
    "        count_matrix = vect.fit_transform(books['soup'])\n",
    "        cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "        books = books.reset_index()\n",
    "        indices = pd.Series(books.index, index=books['Book-Title']).drop_duplicates()\n",
    "        return cosine_sim, books, indices\n",
    "    \n",
    "    def compute_year_similarity(self, book1, book2, value=10):\n",
    "        \"\"\"\n",
    "        Computes similarity score based on year with exponential decay \n",
    "        Args:\n",
    "            book1 (int): year of book1\n",
    "            book2 (int): year of book2\n",
    "        Returns:\n",
    "            sim (int): similarity score\n",
    "        \"\"\"\n",
    "        diff = abs(book1 - book2)\n",
    "        sim = np.exp(-int(diff) / value)\n",
    "        return sim\n",
    "        \n",
    "    def get_recommendations(self, title, topN=10):\n",
    "        \"\"\"\n",
    "        Generate recommendations based on cosine similarity and year similarity based on similar books\n",
    "        Return topN similar Book Titles \n",
    "        Args:\n",
    "            title (str): Book Title to use for comparison\n",
    "            topN (int): how many similar books to recommend \n",
    "        Returns:\n",
    "            indices (pandas df): Top N most similar books to passed in book \n",
    "        \"\"\"\n",
    "        # Get the index of the book that matches the title\n",
    "        idx = self.indices[title]\n",
    "        year = self.books['Year-Of-Publication'] [self.books['Book-Title'] == title]\n",
    "        if isinstance(idx, pd.Series):\n",
    "            idx = idx.iloc[0]\n",
    "            year = year.iloc[0]\n",
    "        # Get the pairwsie similarity scores of all books with that book\n",
    "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
    "        sim_scores = sort_sims(sim_scores, topN=50)\n",
    "\n",
    "        # Get the book indices\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "        year_scores = self.books['Year-Of-Publication'].iloc[book_indices].map(lambda x: self.compute_year_similarity(x, year)).values\n",
    "        # multiply vect scores with year scores \n",
    "        final_scores = list(zip(book_indices, np.array([i[1] for i in sim_scores]) * year_scores))\n",
    "        sim_scores = sort_sims(sim_scores, topN=topN)\n",
    "\n",
    "        # remove current title\n",
    "        book_indices = []\n",
    "        for i, _ in sim_scores:\n",
    "            if i != idx:\n",
    "                book_indices.append(i)\n",
    "                \n",
    "\n",
    "        # Return the top N most similar books\n",
    "        return self.books['Book-Title'].iloc[book_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model \n",
    "content_rec = ContentBased(ratings, books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                           Airframe\n",
       "20                           Timeline\n",
       "60                         Seabiscuit\n",
       "174                             Congo\n",
       "175                Protect and Defend\n",
       "176               The Tall Pine Polka\n",
       "283          Dave Barry in Cyberspace\n",
       "417                      Househusband\n",
       "512    The Mummy or Ramses the Damned\n",
       "611              My Name Is Asher Lev\n",
       "Name: Book-Title, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most similar books to The Hobbit\n",
    "content_rec.get_recommendations(\"Degree of Guilt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kaumudi/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_fields(x, combine=False):\n",
    "    \"\"\"clean string field\"\"\"\n",
    "    x = x.lower()\n",
    "    x = re.sub('[^a-z0-9 ]', '', x)\n",
    "    if combine:\n",
    "        return ''.join(x.replace(' ', '') for x in x).strip()\n",
    "    return x.strip()\n",
    "\n",
    "# sort and return top\n",
    "def sort_sims(sim_scores, topN=10):\n",
    "    \"\"\"sort scores by value of dict and return topN results\"\"\"\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    return sim_scores[:topN+1]\n",
    "        \n",
    "\n",
    "\n",
    "class Hybrid(object):\n",
    "    \"\"\"\n",
    "    Content Based Filtering\n",
    "\n",
    "    Attributes:\n",
    "        ratings (pandas df): ratings dataframe \n",
    "        books (pandas df): book information dataframe \n",
    "        cosine_sim (sparse matrix): cosine similarity matrix\n",
    "        indices (pandas df): Book Title Series \n",
    "    \"\"\"\n",
    "    def __init__(self, ratings, books):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ratings (pandas df): ratings dataframe \n",
    "            books (pandas df): book information dataframe \n",
    "        \"\"\"\n",
    "        self.ratings = ratings\n",
    "        books = self.prepare_data(books, ratings)\n",
    "        self.cosine_sim, self.books, self.indices = self.compute_similarity(books)\n",
    "        \n",
    "    def getdata(self):\n",
    "        return self.userId\n",
    "    \n",
    "    def prepare_data(self, books, ratings, rating_threshold=2):\n",
    "        \"\"\"\n",
    "        Cleans and subsets book dataframe\n",
    "        Args:\n",
    "            ratings (pandas df): ratings dataframe \n",
    "            books (pandas df): book information dataframe\n",
    "            rating_threshold (int): threshold to limit rating count \n",
    "        Returns:\n",
    "            books (pandas df): book information dataframe \n",
    "        \"\"\"\n",
    "        books = books[books['ISBN'].isin(ratings['ISBN'])]\n",
    "        books = books.drop_duplicates(subset=['Book-Title'])\n",
    "        most_popular_ISBN = list(ratings['ISBN'].value_counts()[ratings['ISBN'].value_counts() >= rating_threshold].index)\n",
    "        books = books[books.ISBN.isin(most_popular_ISBN)]\n",
    "        books['Publisher'] = books['Publisher'].map(lambda x: clean_fields(x, combine=True))\n",
    "        books['Book-Author'] = books['Book-Author'].map(lambda x: clean_fields(x, combine=True))\n",
    "        books['Book-Title-Clean'] = books['Book-Title'].map(lambda x: clean_fields(x, combine=False))\n",
    "        books['soup'] = books['Book-Title-Clean'] + ' ' + books['Book-Author'] + ' ' + books['Publisher']\n",
    "        return books \n",
    "        \n",
    "    def compute_similarity(self, books):\n",
    "        \"\"\"\n",
    "        Creates BOW model on the combined book text fields and computes similarity\n",
    "        Args:\n",
    "            books (pandas df): book information dataframe\n",
    "        Returns:\n",
    "            books (pandas df): book information dataframe \n",
    "            cosine_sim (sparse matrix): cosine similarity matrix\n",
    "            indices (pandas df): Book Title Series  \n",
    "        \"\"\"\n",
    "        vect = CountVectorizer(stop_words='english', max_features=1000)\n",
    "        count_matrix = vect.fit_transform(books['soup'])\n",
    "        cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "        books = books.reset_index()\n",
    "        indices = pd.Series(books.index, index=books['Book-Title']).drop_duplicates()\n",
    "        return cosine_sim, books, indices\n",
    "    \n",
    "    def compute_year_similarity(self, book1, book2, value=10):\n",
    "        \"\"\"\n",
    "        Computes similarity score based on year with exponential decay \n",
    "        Args:\n",
    "            book1 (int): year of book1\n",
    "            book2 (int): year of book2\n",
    "        Returns:\n",
    "            sim (int): similarity score\n",
    "        \"\"\"\n",
    "        diff = abs(book1 - book2)\n",
    "        sim = np.exp(-int(diff) / value)\n",
    "        return sim\n",
    "        \n",
    "    def get_recommendations(self, userId, title):\n",
    "        \"\"\"\n",
    "        Generate recommendations based on cosine similarity and year similarity based on similar books\n",
    "        Return topN similar Book Titles \n",
    "        Args:\n",
    "            title (str): Book Title to use for comparison\n",
    "            topN (int): how many similar books to recommend \n",
    "        Returns:\n",
    "            indices (pandas df): Top N most similar books to passed in book \n",
    "        \"\"\"\n",
    "        # Get the index of the book that matches the title\n",
    "        idx = self.indices[title]\n",
    "        year = self.books['Year-Of-Publication'] [self.books['Book-Title'] == title]\n",
    "        if isinstance(idx, pd.Series):\n",
    "            idx = idx.iloc[0]\n",
    "            year = year.iloc[0]\n",
    "        # Get the pairwsie similarity scores of all books with that book\n",
    "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
    "        sim_scores = sort_sims(sim_scores, topN=50)\n",
    "\n",
    "        # Get the book indices\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "        self.books = self.books.iloc[book_indices][['Book-Title', 'Book-Author', 'Year-Of-Publication']]\n",
    "\n",
    "        #Compute the predicted ratings using the SVD filter\n",
    "        self.books['est'] = self.books['Book-Title'].apply(lambda x: model.predict(userId, id_to_title.loc[x]['ISBN']).est)\n",
    "    \n",
    "        #Sort the movies in decreasing order of predicted rating\n",
    "        self.books = self.books.sort_values('est', ascending=False)\n",
    "    \n",
    "        #Return the top 10 movies as recommendations\n",
    "        return self.books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model \n",
    "hybrid_rec = Hybrid(ratings, books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_rec.get_recommendations(1, 'The Hobbit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
